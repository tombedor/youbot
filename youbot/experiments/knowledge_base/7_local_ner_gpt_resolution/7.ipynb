{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import spacy\n",
    "import spacy_llm\n",
    "from spacy_llm.util import assemble\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# add a logger to file notebook.log\n",
    "spacy_llm.logger.addHandler(logging.FileHandler(\"notebook.log\"))\n",
    "spacy_llm.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp = assemble(\"7.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform NER and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from youbot.experiments.pickler import pickled_cache\n",
    "from youbot.store import Store\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@pickled_cache\n",
    "def get_data():\n",
    "    docs = Store().get_archival_messages()\n",
    "    return pd.DataFrame(docs)\n",
    "\n",
    "\n",
    "\n",
    "entities_rows = []\n",
    "relations_rows = []\n",
    "for doc in tqdm(docs):\n",
    "    enriched_doc = nlp(doc)\n",
    "    sleep(0.1) # sleep for openai\n",
    "    ents = enriched_doc.ents\n",
    "    for ent in ents:\n",
    "        entities_rows.append({\"name\": ent.text, \"label\": ent.label_, \"fact\": doc})  # type: ignore\n",
    "    for rel in enriched_doc._.rel:\n",
    "        dep_name = ents[rel.dep].text\n",
    "        dep_label = ents[rel.dep].label_\n",
    "        dest_name = ents[rel.dest].text\n",
    "        dest_label = ents[rel.dest].label_\n",
    "\n",
    "        # ignore self relations\n",
    "        if (dep_name, dep_label) == (dest_name, dest_label):\n",
    "            continue\n",
    "\n",
    "        # ignore dates\n",
    "        if dep_label == \"DATE\" or dest_label == \"DATE\":\n",
    "            continue\n",
    "\n",
    "        relations_rows.append(\n",
    "            {\n",
    "                \"dep_name\": dep_name,\n",
    "                \"dep_label\": dep_label,\n",
    "                \"dest_name\": dest_name,\n",
    "                \"dest_label\": dest_label,\n",
    "                \"rel\": rel.relation,\n",
    "                \"fact\": doc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "entities_df = pd.DataFrame(entities_rows)\n",
    "relations_df = pd.DataFrame(relations_rows)\n",
    "\n",
    "with open('entities.pkl', 'wb') as f:\n",
    "    entities_df.to_pickle(f)\n",
    "    \n",
    "with open('relations.pkl', 'wb') as f:\n",
    "    relations_df.to_pickle(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group facts from entities\n",
    "grouped_entities_df = entities_df.groupby([\"name\", \"label\"]).agg({\"fact\": lambda x: list(x)}).reset_index()\n",
    "grouped_relations_df = (\n",
    "    relations_df.groupby([\"dep_name\", \"dep_label\", \"dest_name\", \"dest_label\", \"rel\"]).agg({\"fact\": lambda x: list(x)}).reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# in some passes, a subset of the labels should be discarded\n",
    "\n",
    "# perhaps, characterize the convo by work, personal, etc and tailor retrieval accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clashing entity types\n",
    "labels_grouped = grouped_entities_df.groupby([\"name\"]).agg({\"label\": lambda x: list(x), \"fact\": lambda x: [item for sublist in x for item in sublist]}).reset_index()\n",
    "clashing_entity_labels = labels_grouped[labels_grouped[\"label\"].apply(lambda x: len(x) > 1)]\n",
    "\n",
    "\n",
    "rels_grouped = grouped_relations_df.groupby([\"dep_name\", \"dest_name\"]).agg({\"rel\": lambda x: list(x), \"fact\": lambda x: [item for sublist in x for item in sublist]}).reset_index()\n",
    "clashing_rels = rels_grouped[rels_grouped[\"rel\"].apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import huggingface_hub\n",
    "from pandas import Series\n",
    "# resolve entities\n",
    "import outlines\n",
    "import outlines.models\n",
    "from pandas import Series\n",
    "huggingface_hub.login(token=os.environ['HF_TOKEN'])\n",
    "model = outlines.models.transformers(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "\n",
    "\n",
    "def pick_winning_label(row: Series) -> str:\n",
    "    labels = row[\"label\"]\n",
    "    name = row[\"name\"]\n",
    "    facts = \"\\n\".join(row[\"fact\"])\n",
    "\n",
    "    prompt = f\"\"\"You are an entity resolution assistant. \n",
    "    You must classify the entity with name = {name}\n",
    "    \n",
    "    Use both your inherent knowledge, and these facts derived from chat logs:\n",
    "    {facts}    \n",
    "    \"\"\"\n",
    "\n",
    "    generator = outlines.generate.choice(model, labels)\n",
    "    answer = generator(prompt)\n",
    "    print(f\"{name}: Choices = {labels}. WINNER = {answer}\")\n",
    "    return answer\n",
    "\n",
    "\n",
    "new_df = clashing_entity_labels.apply(pick_winning_label, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
