{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "use out of the box NER to extract entity names, turn to LLM to label with custom set of entities\n",
    "\n",
    "use outline to run against LM Studio (presumably quantized 7b models)\n",
    "\n",
    "\n",
    "### Observations\n",
    "\n",
    "Memory requirements, at least via spacy-llm, seem really high for running local models\n",
    "\n",
    "unclear if that's because of inefficiencies stemming from spacy library, or inherent to running models\n",
    "\n",
    "wrapping models in libraries seems to generate inefficient use of api's, getting lots of rate limit errors etc with spacy and outline\n",
    "\n",
    "lm studio seems like a good approach to doing openai-like calls without incurring cost or rate limits\n",
    "\n",
    "### renting gpus\n",
    "\n",
    "paperspace is probably still best vs other options, best ui, relatively easy to get notebooks running. some thrash in disconnected kernels seeming to continue to run workloads\n",
    "\n",
    "azure is very enterprisey still, not friendly to solo dev\n",
    "\n",
    "google collab is underbaked, keeps you in their sub-par notebook environment. feels like abandonware/promotionware\n",
    "\n",
    "probably the pricing model everyone lands on is subscription. access to higher GPU RAM machines is gated on higher subscription costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "CONFIG_CONTENT = \"\"\"\n",
    "\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"ner\"]\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.ner]\n",
    "source = \"en_core_web_md\"\n",
    "\n",
    "\n",
    "[initialize]\n",
    "vectors = \"en_core_web_md\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('config.cfg', 'w') as f:\n",
    "    f.write(CONFIG_CONTENT)\n",
    "    \n",
    "    \n",
    "DATA_SOURCE_DIR = ''\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import spacy_llm\n",
    "from spacy_llm.util import assemble\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "config = \"config.cfg\"\n",
    "\n",
    "model_name = \"en_core_web_md\"\n",
    "try:\n",
    "    nlp = assemble(config)\n",
    "except OSError:\n",
    "    spacy.cli.download(model_name)\n",
    "    nlp = assemble(config)\n",
    "\n",
    "# set log level to stream to STDOUT\n",
    "spacy_llm.logger.addHandler(logging.StreamHandler())\n",
    "spacy_llm.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "nlp = assemble(\"config.cfg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine NER\n",
    "\n",
    "resolve disagreements by iterating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = 'msgs.pkl'\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    docs_df = pd.read_pickle(f)\n",
    "    \n",
    "docs = docs_df[0].tolist()\n",
    "\n",
    "\n",
    "entities_rows = []\n",
    "for doc in tqdm(docs):\n",
    "    enriched_doc = nlp(doc)\n",
    "    ents = enriched_doc.ents\n",
    "    for ent in ents:\n",
    "        entities_rows.append({\"name\": ent.text, \"label\": ent.label_, \"fact\": doc})  # type: ignore\n",
    "\n",
    "\n",
    "entities_df = pd.DataFrame(entities_rows)\n",
    "\n",
    "with open('entities.pkl', 'wb') as f:\n",
    "    entities_df.to_pickle(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# refine entity labels\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"lm-studio\"\n",
    "client = OpenAI()\n",
    "model = client.models.list().data[0].id\n",
    "\n",
    "VALID_LABELS = [\n",
    "    \"PERSON\",\n",
    "    \"PET\",\n",
    "    \"ORG\",\n",
    "    \"PRODUCT\",\n",
    "    \"WEBSITE\",\n",
    "    \"GPE\",\n",
    "    \"TVSHOW\",\n",
    "    \"BOOK\",\n",
    "    \"MOVIE\",\n",
    "    \"TECHNICAL_CONCEPT\",\n",
    "    \"MUSICAL_GROUP\",\n",
    "    \"EVENT\"\n",
    "]\n",
    "\n",
    "DISCARD_LABELS = [\n",
    "    \"CARDINAL\",\n",
    "    \"DATE\",\n",
    "    \"TIME\"\n",
    "]\n",
    "\n",
    "VALID_RELATIONSHIPS = {\n",
    "    (\"PERSON\", \"PERSON\"): [\n",
    "        \"is friend to\",\n",
    "        \"is relative of\",\n",
    "        \"is romantic partner of\",\n",
    "        \"is coworker of\",\n",
    "        \"interacted with\",\n",
    "    ],\n",
    "    (\"PERSON\", \"PET\"): [\n",
    "        \"is owner of\",\n",
    "        \"interacted with\",\n",
    "    ],\n",
    "    (\"PERSON\", \"EVENT\"): [\n",
    "        \"attended\",\n",
    "    ],\n",
    "    (\"EVENT\", \"TIME\"): [\n",
    "        \"occured at\"\n",
    "    ],\n",
    "    (\"EVENT\", \"DATE\"): [\n",
    "        \"occured on\"\n",
    "    ]\n",
    "    \n",
    "}\n",
    "\n",
    "# discard entities with any of the discard labels\n",
    "entities_df = entities_df[~entities_df[\"label\"].isin(DISCARD_LABELS)]\n",
    "\n",
    "# get list of unique labels:\n",
    "unique_labels = entities_df[\"name\"].unique()\n",
    "\n",
    "# new dataframe, with a name column and a facts column, which contains the array of facts\n",
    "name_df = entities_df.groupby(\"name\")[\"fact\"].apply(lambda x: pd.unique(x)).reset_index()\n",
    "\n",
    "\n",
    "def chunks(l, n): \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n] \n",
    "# for all entities labeled as person, disambiguate between pets and people \n",
    "def refine_labels(row: pd.Series, current_round = 1, label_choices = VALID_LABELS, classification_tally = {}):    \n",
    "    MAX_ROUNDS = 2\n",
    "    MAX_BATCH_FACTS = 1\n",
    "    MIN_FACTS = 1\n",
    "    \n",
    "    name = row[\"name\"]\n",
    "    fact_set = row[\"fact\"]\n",
    "    \n",
    "    if len(fact_set) < MIN_FACTS:\n",
    "        print('upsampling facts')\n",
    "        fact_list = list(fact_set) * ceil(MIN_FACTS / len(fact_set))\n",
    "    else:\n",
    "        fact_list = list(fact_set)\n",
    "    print(f\"considering name {name}. round {current_round}, label choices: {label_choices}. Number of facts: {len(fact_set)}\")\n",
    "    \n",
    "    \n",
    "    if current_round > MAX_ROUNDS:\n",
    "        print(\"exhausted retries for name {name}, remaining choices are: {classification_tally}\")\n",
    "        max_votes = -float('inf')\n",
    "        winner = None\n",
    "        for label, votes in classification_tally.items():\n",
    "            if votes > max_votes:\n",
    "                max_votes = votes\n",
    "                winner = label\n",
    "        return winner\n",
    "    \n",
    "    \n",
    "    random.shuffle(fact_set)\n",
    "    random.shuffle(label_choices)\n",
    "    labels_str = \", \".join(label_choices)\n",
    "    \n",
    "    candidates = set()\n",
    "    for fact_chunk in chunks(fact_list, MAX_BATCH_FACTS):\n",
    "        facts_str = \"\\n\".join(set(fact_chunk))\n",
    "        prompt = f\"\"\"You are an entity resolution assistant. \n",
    "        You must classify the entity with name = {name}\n",
    "        \n",
    "        The valid choices are: {labels_str}\n",
    "        \n",
    "        \n",
    "        Use both your inherent knowledge, and these facts derived from chat logs:\n",
    "        {facts_str}\n",
    "        \n",
    "        Your response should begin with just one word from the following choices: {labels_str}, then should follow with an explanation of your reasoning.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]).choices[0].message.content\n",
    "        assert(response)\n",
    "        print(f\"***\\nname: {name}\\n\\nfacts: {facts_str}\\n\\nresponse: {response}\\n\\n***\\n\")\n",
    "        \n",
    "        # whichever label appears first wins\n",
    "        winner = None\n",
    "        min_idx = float('inf')\n",
    "        for label in label_choices:\n",
    "            if label in response:\n",
    "                idx = response.index(label)\n",
    "                if idx < min_idx:\n",
    "                    min_idx = idx\n",
    "                    winner = label\n",
    "        if winner:\n",
    "            classification_tally[winner] = classification_tally.get(winner, 0) + 1\n",
    "            candidates.add(winner)\n",
    "    if len(candidates) == 0:\n",
    "        print('no candidates found, retrying')\n",
    "        return refine_labels(row, current_round + 1, label_choices, classification_tally)\n",
    "    elif len(candidates) == 1:\n",
    "        winner = candidates.pop()\n",
    "        print(f\"winning candidate found: {winner}\")\n",
    "        return winner\n",
    "    else:\n",
    "        print(f\"narrowed to candidates: {candidates}\")\n",
    "        \n",
    "        return refine_labels(row, current_round + 1, list(candidates), classification_tally)\n",
    "        \n",
    "# curl http://localhost:1234/v1/chat/completions \\\n",
    "#   -H \"Content-Type: application/json\" \\\n",
    "#   -d '{ \n",
    "#     \"model\": \"lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF\",\n",
    "#     \"messages\": [ \n",
    "#       { \"role\": \"system\", \"content\": \"Always answer in rhymes.\" },\n",
    "#       { \"role\": \"user\", \"content\": \"Introduce yourself.\" }\n",
    "#     ], \n",
    "#     \"temperature\": 0.7, \n",
    "#     \"max_tokens\": -1,\n",
    "#     \"stream\": true\n",
    "# }'\n",
    "\n",
    "# apply the refine_labels function to each row in the name_df\n",
    "name_df['label'] = name_df.apply(refine_labels, axis=1)\n",
    "with open('refined_labels.pkl', 'wb') as f:\n",
    "    name_df.to_pickle(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# refine entity labels\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "person_labels = [\"PERSON\", \"PET\"]\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"lm-studio\"\n",
    "# model = \"LM Studio Community/Meta-Llama-3-8B-Instruct-GGUF\"\n",
    "model = \"TheBloke/Mistral-7B-Instruct-v0.2-GGUF\"\n",
    "client = OpenAI()\n",
    "\n",
    "\n",
    "\n",
    "# for all entities labeled as person, disambiguate between pets and people \n",
    "def refine_labels(row: pd.Series):\n",
    "    name = row[\"name\"]\n",
    "    label = row[\"label\"]\n",
    "    if label == \"PERSON\" and name != \"Tom\":\n",
    "        prompt = f\"\"\"You are an entity resolution assistant. \n",
    "        You must classify the entity with name = {name}\n",
    "        \n",
    "        The valid choices are: PERSON, PET, UNKNOWN\n",
    "        A previous classifier labeled this entity as: {label}\n",
    "        \n",
    "        Use both your inherent knowledge, and these facts derived from chat logs:\n",
    "        {row[\"fact\"]} \n",
    "        \n",
    "        The first word of your response should be one of the following: PERSON, PET, UNKNOWN\n",
    "        Follow this with explanation of your reasoning.\n",
    "        \"\"\"\n",
    "\n",
    "        answer = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]).choices[0].message.content\n",
    "        print(f\"NAME: {name}\\nFact:{row['fact']}.\\n\\n***\\nWINNER = {answer}\\n***\")\n",
    "\n",
    "        return answer\n",
    "    else:\n",
    "        return label\n",
    "\n",
    "        \n",
    "# apply the function to all rows\n",
    "# add column, new_label\n",
    "entities_df[\"new_label\"] = entities_df.apply(refine_labels, axis=1)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
