{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "use out of the box NER to extract entity names, turn to LLM to label with custom set of entities\n",
    "\n",
    "use outline to run against LM Studio (presumably quantized 7b models)\n",
    "\n",
    "\n",
    "### Observations\n",
    "\n",
    "Memory requirements, at least via spacy-llm, seem really high for running local models\n",
    "\n",
    "unclear if that's because of inefficiencies stemming from spacy library, or inherent to running models\n",
    "\n",
    "wrapping models in libraries seems to generate inefficient use of api's, getting lots of rate limit errors etc with spacy and outline\n",
    "\n",
    "lm studio seems like a good approach to doing openai-like calls without incurring cost or rate limits\n",
    "\n",
    "### renting gpus\n",
    "\n",
    "paperspace is probably still best vs other options, best ui, relatively easy to get notebooks running. some thrash in disconnected kernels seeming to continue to run workloads\n",
    "\n",
    "azure is very enterprisey still, not friendly to solo dev\n",
    "\n",
    "google collab is underbaked, keeps you in their sub-par notebook environment. feels like abandonware/promotionware\n",
    "\n",
    "probably the pricing model everyone lands on is subscription. access to higher GPU RAM machines is gated on higher subscription costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "CONFIG_CONTENT = \"\"\"\n",
    "\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"ner\"]\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.ner]\n",
    "source = \"en_core_web_md\"\n",
    "\n",
    "\n",
    "[initialize]\n",
    "vectors = \"en_core_web_md\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('config.cfg', 'w') as f:\n",
    "    f.write(CONFIG_CONTENT)\n",
    "    \n",
    "    \n",
    "DATA_SOURCE_DIR = ''\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import spacy_llm\n",
    "from spacy_llm.util import assemble\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "config = \"config.cfg\"\n",
    "\n",
    "model_name = \"en_core_web_md\"\n",
    "try:\n",
    "    nlp = assemble(config)\n",
    "except OSError:\n",
    "    spacy.cli.download(model_name)\n",
    "    nlp = assemble(config)\n",
    "\n",
    "# set log level to stream to STDOUT\n",
    "spacy_llm.logger.addHandler(logging.StreamHandler())\n",
    "spacy_llm.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "nlp = assemble(\"config.cfg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine NER\n",
    "\n",
    "resolve disagreements by iterating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:00<00:00, 203.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = 'msgs.pkl'\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    docs_df = pd.read_pickle(f)\n",
    "    \n",
    "docs = docs_df[0].tolist()\n",
    "\n",
    "\n",
    "entities_rows = []\n",
    "for doc in tqdm(docs):\n",
    "    enriched_doc = nlp(doc)\n",
    "    ents = enriched_doc.ents\n",
    "    for ent in ents:\n",
    "        entities_rows.append({\"name\": ent.text, \"label\": ent.label_, \"fact\": doc, \"enriched_doc\": enriched_doc})  # type: ignore\n",
    "\n",
    "\n",
    "entities_df = pd.DataFrame(entities_rows)\n",
    "\n",
    "with open('entities.pkl', 'wb') as f:\n",
    "    entities_df.to_pickle(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# refine entity labels\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"lm-studio\"\n",
    "client = OpenAI()\n",
    "model = client.models.list().data[0].id\n",
    "\n",
    "VALID_LABELS = [\n",
    "    \"PERSON\",\n",
    "    \"PET\",\n",
    "    \"ORG\",\n",
    "    \"PRODUCT\",\n",
    "    \"WEBSITE\",\n",
    "    \"GPE\",\n",
    "    \"TVSHOW\",\n",
    "    \"BOOK\",\n",
    "    \"MOVIE\",\n",
    "    \"TECHNICAL_CONCEPT\",\n",
    "    \"MUSICAL_GROUP\",\n",
    "    \"EVENT\"\n",
    "]\n",
    "\n",
    "DISCARD_LABELS = [\n",
    "    \"CARDINAL\",\n",
    "    \"DATE\",\n",
    "    \"TIME\"\n",
    "]\n",
    "\n",
    "# discard entities with any of the discard labels\n",
    "entities_df = entities_df[~entities_df[\"label\"].isin(DISCARD_LABELS)]\n",
    "\n",
    "# get list of unique labels:\n",
    "unique_labels = entities_df[\"name\"].unique()\n",
    "\n",
    "# new dataframe, with a name column and a facts column, which contains the array of facts\n",
    "name_df = entities_df.groupby(\"name\")[\"fact\"].apply(lambda x: pd.unique(x)).reset_index()\n",
    "\n",
    "\n",
    "entity_rows = []\n",
    "for _, row in tqdm(entities_df.iterrows()):\n",
    "    name = row['name']\n",
    "    fact = row['fact']\n",
    "    \n",
    "\n",
    "    if name == 'Tom':\n",
    "        entity_rows.append({\"name\": name, 'label': 'PERSON', \"fact\": fact, 'score': 100})\n",
    "        continue\n",
    "\n",
    "    label_choices = VALID_LABELS.copy()\n",
    "    random.shuffle(label_choices)\n",
    "    labels_str = \", \".join(label_choices)\n",
    "    candidates = {}\n",
    "    \n",
    "    prompt = f\"\"\"You are an entity resolution assistant. \n",
    "    You must classify the entity with name = {name}\n",
    "    \n",
    "    The valid choices are: {labels_str}\n",
    "    \n",
    "    \n",
    "    Use both your inherent knowledge, and this facts derived from chat logs:\n",
    "    {fact}\n",
    "    \n",
    "    Your response should begin with just one word from the following choices: {labels_str}.\n",
    "    Then, a score from 1 to 100, where 100 is the most confident and 1.\n",
    "    Then should follow with a short explanation of your reasoning.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]).choices[0].message.content\n",
    "    assert(response)\n",
    "    print(f\"***\\nname: {name}\\n\\nfact: {fact}\\n\\nresponse: {response}\\n\\n***\\n\")\n",
    "    \n",
    "    # whichever label appears first wins\n",
    "    winner = 'None'\n",
    "    min_idx = float('inf')\n",
    "    for label in label_choices:\n",
    "        if label in response:\n",
    "            idx = response.index(label)\n",
    "            if idx < min_idx:\n",
    "                min_idx = idx\n",
    "                winner = label\n",
    "    \n",
    "    try:\n",
    "        score = int(re.search(r'\\d+', response).group())\n",
    "    except AttributeError:\n",
    "        score = 0\n",
    "        \n",
    "    entity_rows.append({\"name\": name, 'label': winner, \"fact\": fact, 'score': score})\n",
    "            \n",
    "with open('refined_labels.pkl', 'wb') as f:\n",
    "    pd.DataFrame(entity_rows).to_pickle(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersecting facts for Allison and Justina: {\"On 2024-02-26, Tom shared that he and Justina had a weekend full of dog activities, as they were taking care of his sister Allison's dog, Cesar. This presents an addition to Tom's pet-friendly lifestyle and his on-going family connections.\"}\n",
      "Entity 1: Allison, a PERSON. Entity 2: Justina. A PERSON. Fact: On 2024-02-26, Tom shared that he and Justina had a weekend full of dog activities, as they were taking care of his sister Allison's dog, Cesar. This presents an addition to Tom's pet-friendly lifestyle and his on-going family connections.\n",
      "***\n",
      "name: Allison, Justina\n",
      "\n",
      "response: IS_RELATIVE_OF\n",
      "99\n",
      "\n",
      "Based on the provided information, I have classified Allison as Tom's sister, which makes Justina her caretaker or a friend/family member helping with dog care, rather than a romantic partner or coworker. The fact that they took care of Cesar, Allison's dog, suggests a familial connection between Tom and Allison, making it likely that Justina is also connected to the family through Tom's relationship with Allison.\n",
      "\n",
      "***\n",
      "\n",
      "{'entity_1': 'Allison', 'entity_2': 'Justina', 'relationship': 'IS_RELATIVE_OF', 'fact': \"On 2024-02-26, Tom shared that he and Justina had a weekend full of dog activities, as they were taking care of his sister Allison's dog, Cesar. This presents an addition to Tom's pet-friendly lifestyle and his on-going family connections.\", 'score': 99}\n",
      "Intersecting facts for Allison and Tom: {\"On 2024-02-26, Tom shared that he and Justina had a weekend full of dog activities, as they were taking care of his sister Allison's dog, Cesar. This presents an addition to Tom's pet-friendly lifestyle and his on-going family connections.\"}\n",
      "Entity 1: Allison, a PERSON. Entity 2: Tom. A PERSON. Fact: On 2024-02-26, Tom shared that he and Justina had a weekend full of dog activities, as they were taking care of his sister Allison's dog, Cesar. This presents an addition to Tom's pet-friendly lifestyle and his on-going family connections.\n",
      "***\n",
      "name: Allison, Tom\n",
      "\n",
      "response: 'IS_RELATIVE_OF', 90\n",
      "\n",
      "Tom and Allison are siblings as mentioned in the chat logs: \"taking care of his sister Allison's dog, Cesar\". This indicates that Tom has a familial relationship with Allison.\n",
      "\n",
      "Score: 90 (I'm very confident in this choice because the information provided explicitly states their sibling relationship.)\n",
      "\n",
      "Explanation: The shared experience of taking care of Allison's dog and the mention of her as his sister suggest a close family bond between Tom and Allison.\n",
      "\n",
      "***\n",
      "\n",
      "{'entity_1': 'Allison', 'entity_2': 'Tom', 'relationship': 'IS_RELATIVE_OF', 'fact': \"On 2024-02-26, Tom shared that he and Justina had a weekend full of dog activities, as they were taking care of his sister Allison's dog, Cesar. This presents an addition to Tom's pet-friendly lifestyle and his on-going family connections.\", 'score': 90}\n",
      "Intersecting facts for Evelyn and Leo: {\"On 2024-02-04, Tom added the 'add_list_item' function to my capabilities. He subsequently asked to add 'Leo' and 'Evelyn' to his 'potential child names' list. Both names were successfully added.\"}\n",
      "Entity 1: Evelyn, a PERSON. Entity 2: Leo. A PERSON. Fact: On 2024-02-04, Tom added the 'add_list_item' function to my capabilities. He subsequently asked to add 'Leo' and 'Evelyn' to his 'potential child names' list. Both names were successfully added.\n",
      "***\n",
      "name: Evelyn, Leo\n",
      "\n",
      "response: 'IS_RELATIVE_OF', 80\n",
      "\n",
      "I chose 'IS_RELATIVE_OF' because Tom mentioned adding \"Leo\" and \"Evelyn\" to his \"potential child names\" list, which implies that Evelyn and Leo are potential parents or relatives. The fact that they were added together suggests a familial relationship between the two entities. Although there is no explicit confirmation of their biological relationship, this context provides a strong indication of a relative connection.\n",
      "\n",
      "***\n",
      "\n",
      "{'entity_1': 'Evelyn', 'entity_2': 'Leo', 'relationship': 'IS_RELATIVE_OF', 'fact': \"On 2024-02-04, Tom added the 'add_list_item' function to my capabilities. He subsequently asked to add 'Leo' and 'Evelyn' to his 'potential child names' list. Both names were successfully added.\", 'score': 80}\n",
      "Intersecting facts for Evelyn and Tom: {\"On 2024-02-04, Tom added the 'add_list_item' function to my capabilities. He subsequently asked to add 'Leo' and 'Evelyn' to his 'potential child names' list. Both names were successfully added.\"}\n",
      "Entity 1: Evelyn, a PERSON. Entity 2: Tom. A PERSON. Fact: On 2024-02-04, Tom added the 'add_list_item' function to my capabilities. He subsequently asked to add 'Leo' and 'Evelyn' to his 'potential child names' list. Both names were successfully added.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "VALID_RELATIONSHIPS = {\n",
    "    (\"PERSON\", \"PERSON\"): [\n",
    "        \"IS_FRIEND_TO\",\n",
    "        \"IS_RELATIVE_OF\",\n",
    "        \"IS_ROMANTIC_PARTNER_OF\",\n",
    "        \"IS_COWORKER_OF\",\n",
    "        \"FOLLOWS_IN_MEDIA\",\n",
    "        \"IS_SAME_PERSON_AS\",\n",
    "    ],\n",
    "    (\"PERSON\", \"PET\"): [\n",
    "        \"is owner of\",\n",
    "        \"interacted with\",\n",
    "        \"took care of\",\n",
    "    ],\n",
    "    (\"PERSON\", \"EVENT\"): [\n",
    "        \"attended\",\n",
    "    ],\n",
    "    (\"EVENT\", \"TIME\"): [\n",
    "        \"occured at\"\n",
    "    ],\n",
    "    (\"EVENT\", \"DATE\"): [\n",
    "        \"occured on\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "resolve_entities = pd.read_pickle('refined_labels.pkl')['name']\n",
    "# first element in the tuple is the label\n",
    "resolved_labels = pd.read_pickle('refined_labels.pkl')['label'].apply(lambda x: x[0])\n",
    "\n",
    "resolved_entity_df = pd.DataFrame({\"name\": resolve_entities, \"label\": resolved_labels})\n",
    "\n",
    "relation_rows = []\n",
    "\n",
    "for label_1, label_2 in VALID_RELATIONSHIPS.keys():\n",
    "    entity_1 = resolved_entity_df[resolved_entity_df[\"label\"] == label_1]\n",
    "    entity_2 = resolved_entity_df[resolved_entity_df[\"label\"] == label_2]\n",
    "\n",
    "    for _, row_1 in entity_1.iterrows():\n",
    "        for _, row_2 in entity_2.iterrows():\n",
    "            name_1 = row_1['name']\n",
    "            name_2 = row_2['name']\n",
    "            if name_1 == name_2:\n",
    "                continue\n",
    "            facts_1 = entities_df[entities_df[\"name\"] == name_1][\"fact\"]\n",
    "            facts_2 = entities_df[entities_df[\"name\"] == name_2][\"fact\"]\n",
    "            \n",
    "            intersecting_facts = set(facts_1).intersection(set(facts_2))\n",
    "            \n",
    "            if len(intersecting_facts) == 0:\n",
    "                continue\n",
    "\n",
    "            print(f\"Intersecting facts for {name_1} and {name_2}: {intersecting_facts}\")\n",
    "        \n",
    "            relation_candidates = {}\n",
    "            \n",
    "            for fact in intersecting_facts:\n",
    "                print(f\"Entity 1: {row_1['name']}, a {label_1}. Entity 2: {row_2['name']}. A {label_2}. Fact: {fact}\")\n",
    "                prompt = f\"\"\"You are an entity resolution assistant. \n",
    "                You must classify the relationship between two entities:\n",
    "                Entity 1: name = {row_1['name']}, type = {label_1} \n",
    "                Entity 2: name = {row_2['name']}, type = {label_2}\n",
    "            \n",
    "                The valid choices are: {VALID_RELATIONSHIPS[(label_1, label_2)]}. If none fit specify NONE.\n",
    "                \n",
    "                Use both your inherent knowledge, and this fact derived from chat logs:\n",
    "                {fact}\n",
    "                \n",
    "                Your response begin with one of the following choices: {VALID_RELATIONSHIPS[(label_1, label_2)]}, NONE. \n",
    "                A score from 1 to 100 should follow. 100 means you are very confident in your choice, 1 means you are not confident at all.\n",
    "                Then it should follow with a short explanation of your reasoning.\n",
    "                \"\"\"\n",
    "                \n",
    "                response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]).choices[0].message.content\n",
    "                assert(response)\n",
    "                print(f\"***\\nname: {row_1['name']}, {row_2['name']}\\n\\nresponse: {response}\\n\\n***\\n\")\n",
    "                \n",
    "                # whichever label appears first wins\n",
    "                winner = None\n",
    "                min_idx = float('inf')\n",
    "                for label in VALID_RELATIONSHIPS[(label_1, label_2)]:\n",
    "                    if label in response:\n",
    "                        idx = response.index(label)\n",
    "                        if idx < min_idx:\n",
    "                            min_idx = idx\n",
    "                            winner = label\n",
    "                # score is regex match for first number in the response\n",
    "                try:\n",
    "                    score = int(re.search(r'\\d+', response).group())\n",
    "                except AttributeError:\n",
    "                    score = 0\n",
    "                    \n",
    "                row = {\"entity_1\": row_1['name'], \"entity_2\": row_2['name'], \"relationship\": winner, 'fact': fact, 'score': score}\n",
    "                print(row)\n",
    "                relation_rows.append(row)\n",
    "            \n",
    "\n",
    "# data frame from list of rows (each entry is a dict)\n",
    "relation_df = pd.DataFrame(relation_rows)\n",
    "with open('relationships.pkl', 'wb') as f:\n",
    "    relation_df.to_pickle(f)\n",
    "            \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>fact</th>\n",
       "      <th>enriched_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-27</td>\n",
       "      <td>DATE</td>\n",
       "      <td>On 2024-01-27, Tom expressed a preference for ...</td>\n",
       "      <td>(On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tom</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>On 2024-01-27, Tom expressed a preference for ...</td>\n",
       "      <td>(On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neo4j Community</td>\n",
       "      <td>ORG</td>\n",
       "      <td>On 2024-01-27, Tom expressed a preference for ...</td>\n",
       "      <td>(On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JanusGraph</td>\n",
       "      <td>ORG</td>\n",
       "      <td>On 2024-01-27, Tom expressed a preference for ...</td>\n",
       "      <td>(On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JanusGraph</td>\n",
       "      <td>ORG</td>\n",
       "      <td>On 2024-01-27, Tom expressed a preference for ...</td>\n",
       "      <td>(On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>DATE</td>\n",
       "      <td>On 2024-04-29, Tom asked about applying a func...</td>\n",
       "      <td>(On, 2024, -, 04, -, 29, ,, Tom, asked, about,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Tom</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>On 2024-04-29, Tom asked about applying a func...</td>\n",
       "      <td>(On, 2024, -, 04, -, 29, ,, Tom, asked, about,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>one</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>On 2024-04-29, Tom asked about applying a func...</td>\n",
       "      <td>(On, 2024, -, 04, -, 29, ,, Tom, asked, about,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Sam</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>On 2024-04-29, Tom asked about applying a func...</td>\n",
       "      <td>(On, 2024, -, 04, -, 29, ,, Tom, asked, about,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Series</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>On 2024-04-29, Tom asked about applying a func...</td>\n",
       "      <td>(On, 2024, -, 04, -, 29, ,, Tom, asked, about,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name     label  \\\n",
       "0         2024-01-27      DATE   \n",
       "1                Tom    PERSON   \n",
       "2    Neo4j Community       ORG   \n",
       "3         JanusGraph       ORG   \n",
       "4         JanusGraph       ORG   \n",
       "..               ...       ...   \n",
       "688       2024-04-29      DATE   \n",
       "689              Tom    PERSON   \n",
       "690              one  CARDINAL   \n",
       "691              Sam    PERSON   \n",
       "692           Series     EVENT   \n",
       "\n",
       "                                                  fact  \\\n",
       "0    On 2024-01-27, Tom expressed a preference for ...   \n",
       "1    On 2024-01-27, Tom expressed a preference for ...   \n",
       "2    On 2024-01-27, Tom expressed a preference for ...   \n",
       "3    On 2024-01-27, Tom expressed a preference for ...   \n",
       "4    On 2024-01-27, Tom expressed a preference for ...   \n",
       "..                                                 ...   \n",
       "688  On 2024-04-29, Tom asked about applying a func...   \n",
       "689  On 2024-04-29, Tom asked about applying a func...   \n",
       "690  On 2024-04-29, Tom asked about applying a func...   \n",
       "691  On 2024-04-29, Tom asked about applying a func...   \n",
       "692  On 2024-04-29, Tom asked about applying a func...   \n",
       "\n",
       "                                          enriched_doc  \n",
       "0    (On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...  \n",
       "1    (On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...  \n",
       "2    (On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...  \n",
       "3    (On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...  \n",
       "4    (On, 2024, -, 01, -, 27, ,, Tom, expressed, a,...  \n",
       "..                                                 ...  \n",
       "688  (On, 2024, -, 04, -, 29, ,, Tom, asked, about,...  \n",
       "689  (On, 2024, -, 04, -, 29, ,, Tom, asked, about,...  \n",
       "690  (On, 2024, -, 04, -, 29, ,, Tom, asked, about,...  \n",
       "691  (On, 2024, -, 04, -, 29, ,, Tom, asked, about,...  \n",
       "692  (On, 2024, -, 04, -, 29, ,, Tom, asked, about,...  \n",
       "\n",
       "[693 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df\n",
    "\n",
    "\n",
    "# check logic,\n",
    "\n",
    "# multiple romantic partners, romantic partners that are also a sibling, familial relationships\n",
    "\n",
    "\n",
    "# need to hone by confidence score or something similar, not every fact is equally important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
