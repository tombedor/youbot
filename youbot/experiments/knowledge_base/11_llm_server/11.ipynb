{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea\n",
    "\n",
    "use out of the box NER to extract entity names, turn to LLM to label with custom set of entities\n",
    "\n",
    "use outline to run against LM Studio (presumably quantized 7b models)\n",
    "\n",
    "\n",
    "### Observations\n",
    "\n",
    "Memory requirements, at least via spacy-llm, seem really high for running local models\n",
    "\n",
    "unclear if that's because of inefficiencies stemming from spacy library, or inherent to running models\n",
    "\n",
    "wrapping models in libraries seems to generate inefficient use of api's, getting lots of rate limit errors etc with spacy and outline\n",
    "\n",
    "lm studio seems like a good approach to doing openai-like calls without incurring cost or rate limits\n",
    "\n",
    "### renting gpus\n",
    "\n",
    "paperspace is probably still best vs other options, best ui, relatively easy to get notebooks running. some thrash in disconnected kernels seeming to continue to run workloads\n",
    "\n",
    "azure is very enterprisey still, not friendly to solo dev\n",
    "\n",
    "google collab is underbaked, keeps you in their sub-par notebook environment. feels like abandonware/promotionware\n",
    "\n",
    "probably the pricing model everyone lands on is subscription. access to higher GPU RAM machines is gated on higher subscription costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "CONFIG_CONTENT = \"\"\"\n",
    "\n",
    "[nlp]\n",
    "lang = \"en\"\n",
    "pipeline = [\"ner\"]\n",
    "\n",
    "[components]\n",
    "\n",
    "[components.ner]\n",
    "source = \"en_core_web_md\"\n",
    "\n",
    "\n",
    "[initialize]\n",
    "vectors = \"en_core_web_md\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('config.cfg', 'w') as f:\n",
    "    f.write(CONFIG_CONTENT)\n",
    "    \n",
    "    \n",
    "DATA_SOURCE_DIR = ''\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## install requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import spacy_llm\n",
    "from spacy_llm.util import assemble\n",
    "import spacy\n",
    "\n",
    "\n",
    "\n",
    "config = \"config.cfg\"\n",
    "\n",
    "model_name = \"en_core_web_md\"\n",
    "try:\n",
    "    nlp = assemble(config)\n",
    "except OSError:\n",
    "    spacy.cli.download(model_name)\n",
    "    nlp = assemble(config)\n",
    "\n",
    "# set log level to stream to STDOUT\n",
    "spacy_llm.logger.addHandler(logging.StreamHandler())\n",
    "spacy_llm.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "nlp = assemble(\"config.cfg\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial pass, identify labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = 'msgs.pkl'\n",
    "\n",
    "with open(DATA_PATH, 'rb') as f:\n",
    "    docs_df = pd.read_pickle(f)\n",
    "    \n",
    "docs = docs_df[0].tolist()\n",
    "\n",
    "\n",
    "entities_rows = []\n",
    "for doc in tqdm(docs):\n",
    "    enriched_doc = nlp(doc)\n",
    "    ents = enriched_doc.ents\n",
    "    for ent in ents:\n",
    "        entities_rows.append({\"name\": ent.text, \"label\": ent.label_, \"fact\": doc, \"enriched_doc\": enriched_doc})  # type: ignore\n",
    "\n",
    "\n",
    "entities_df = pd.DataFrame(entities_rows)\n",
    "\n",
    "with open('entities.pkl', 'wb') as f:\n",
    "    entities_df.to_pickle(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refine labels\n",
    "\n",
    "redo labels along customized labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# refine entity labels\n",
    "import os\n",
    "import re\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"lm-studio\"\n",
    "client = OpenAI()\n",
    "model = client.models.list().data[0].id\n",
    "\n",
    "VALID_LABELS = [\n",
    "    \"PERSON\",\n",
    "    \"PET\",\n",
    "    \"ORG\",\n",
    "    \"PRODUCT\",\n",
    "    \"WEBSITE\",\n",
    "    \"GPE\",\n",
    "    \"TVSHOW\",\n",
    "    \"BOOK\",\n",
    "    \"MOVIE\",\n",
    "    \"TECHNICAL_CONCEPT\",\n",
    "    \"MUSICAL_GROUP\",\n",
    "    \"EVENT\"\n",
    "]\n",
    "\n",
    "DISCARD_LABELS = [\n",
    "    \"CARDINAL\",\n",
    "    \"DATE\",\n",
    "    \"TIME\"\n",
    "]\n",
    "\n",
    "# discard entities with any of the discard labels\n",
    "entities_df = entities_df[~entities_df[\"label\"].isin(DISCARD_LABELS)]\n",
    "\n",
    "# get list of unique labels:\n",
    "unique_labels = entities_df[\"name\"].unique()\n",
    "\n",
    "# new dataframe, with a name column and a facts column, which contains the array of facts\n",
    "name_df = entities_df.groupby(\"name\")[\"fact\"].apply(lambda x: pd.unique(x)).reset_index()\n",
    "\n",
    "\n",
    "entity_rows = []\n",
    "for _, row in tqdm(entities_df.iterrows()):\n",
    "    name = row['name']\n",
    "    fact = row['fact']\n",
    "    \n",
    "\n",
    "    if name == 'Tom':\n",
    "        entity_rows.append({\"name\": name, 'label': 'PERSON', \"fact\": fact, 'score': 100})\n",
    "        continue\n",
    "\n",
    "    label_choices = VALID_LABELS.copy()\n",
    "    random.shuffle(label_choices)\n",
    "    labels_str = \", \".join(label_choices)\n",
    "    candidates = {}\n",
    "    \n",
    "    prompt = f\"\"\"You are an entity resolution assistant. \n",
    "    You must classify the entity with name = {name}\n",
    "    \n",
    "    The valid choices are: {labels_str}\n",
    "    \n",
    "    \n",
    "    Use both your inherent knowledge, and this facts derived from chat logs:\n",
    "    {fact}\n",
    "    \n",
    "    Your response should begin with just one word from the following choices: {labels_str}.\n",
    "    Then, a score from 1 to 100, where 100 is the most confident and 1.\n",
    "    Then should follow with a short explanation of your reasoning.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]).choices[0].message.content\n",
    "    assert(response)\n",
    "    print(f\"***\\nname: {name}\\n\\nfact: {fact}\\n\\nresponse: {response}\\n\\n***\\n\")\n",
    "    \n",
    "    # whichever label appears first wins\n",
    "    winner = 'None'\n",
    "    min_idx = float('inf')\n",
    "    for label in label_choices:\n",
    "        if label in response:\n",
    "            idx = response.index(label)\n",
    "            if idx < min_idx:\n",
    "                min_idx = idx\n",
    "                winner = label\n",
    "    \n",
    "    try:\n",
    "        score = int(re.search(r'\\d+', response).group())\n",
    "    except AttributeError:\n",
    "        score = 0\n",
    "        \n",
    "    entity_rows.append({\"name\": name, 'label': winner, \"fact\": fact, 'score': score})\n",
    "            \n",
    "with open('refined_labels.pkl', 'wb') as f:\n",
    "    pd.DataFrame(entity_rows).to_pickle(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# determine winning labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "with open('refined_labels.pkl', 'rb') as f:\n",
    "    raw_entity_with_labels = pd.read_pickle(f)\n",
    "    \n",
    "# facts and set of entities\n",
    "facts_with_entities = raw_entity_with_labels.groupby(\"fact\")[\"name\"].apply(lambda x: set(x)).reset_index()\n",
    "    \n",
    "entity_names_and_labels_summed_scores = raw_entity_with_labels.groupby([\"name\", \"label\"])[\"score\"].sum().reset_index()\n",
    "\n",
    "# for each entity name, pick label with highest score\n",
    "entity_with_labels = entity_names_and_labels_summed_scores.sort_values('score', ascending=False).drop_duplicates('name')\n",
    "entity_with_labels = entity_with_labels.drop('score', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine raw relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation relationship between Justina and Tom\n",
      "{'entity_1': 'Justina', 'entity_2': 'Tom', 'relationship': 'IS_ROMANTIC_PARTNER_OF', 'fact': 'In late March 2024, Tom started working on personal vows for Justina, indicating an upcoming special occasion or a renewed commitment in their relationship.', 'score': 80}\n",
      "evaluation relationship between Tom and Justina\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [01:02,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'entity_1': 'Tom', 'entity_2': 'Justina', 'relationship': 'IS_ROMANTIC_PARTNER_OF', 'fact': 'In late March 2024, Tom started working on personal vows for Justina, indicating an upcoming special occasion or a renewed commitment in their relationship.', 'score': 80}\n",
      "evaluation relationship between Sam and Elroy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import random\n",
    "\n",
    "\n",
    "VALID_RELATIONSHIPS = {\n",
    "    (\"PERSON\", \"PERSON\"): [\n",
    "        \"IS_FRIEND_TO\",\n",
    "        \"IS_RELATIVE_OF\",\n",
    "        \"IS_ROMANTIC_PARTNER_OF\",\n",
    "        \"IS_COWORKER_OF\",\n",
    "        \"FOLLOWS_IN_MEDIA\",\n",
    "        \"IS_SAME_PERSON_AS\",\n",
    "    ],\n",
    "    (\"PERSON\", \"PET\"): [\n",
    "        \"IS_OWNER_OF\",\n",
    "        \"TOOK_CARE_OF\",\n",
    "    ],\n",
    "    (\"PERSON\", \"EVENT\"): [\n",
    "        \"ATTENDED\",\n",
    "        \"HOSTED\",\n",
    "    ],\n",
    "    (\"EVENT\", \"TIME\"): [\n",
    "        \"OCCURRED_AT\"\n",
    "    ],\n",
    "    (\"EVENT\", \"DATE\"): [\n",
    "        \"OCCURED_ON\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "os.environ['OPENAI_BASE_URL'] = \"http://localhost:1234/v1\"\n",
    "os.environ['OPENAI_API_KEY'] = \"lm-studio\"\n",
    "client = OpenAI()\n",
    "model = client.models.list().data[0].id\n",
    "\n",
    "resolve_entities = pd.read_pickle('refined_labels.pkl')['name']\n",
    "# first element in the tuple is the label\n",
    "resolved_labels = pd.read_pickle('refined_labels.pkl')['label'].apply(lambda x: x[0])\n",
    "\n",
    "resolved_entity_df = pd.DataFrame({\"name\": resolve_entities, \"label\": resolved_labels})\n",
    "\n",
    "relation_rows = []\n",
    "for _, row in tqdm(facts_with_entities.iterrows()):\n",
    "    fact = row['fact']\n",
    "    entities = row['name']\n",
    "    \n",
    "    if len(entities) < 2:\n",
    "        continue\n",
    "    \n",
    "    for entity_1 in entities:\n",
    "        for entity_2 in entities:\n",
    "            if entity_1 == entity_2:\n",
    "                continue\n",
    "            label_1 = entity_with_labels[entity_with_labels[\"name\"] == entity_1][\"label\"].values[0]\n",
    "            label_2 = entity_with_labels[entity_with_labels[\"name\"] == entity_2][\"label\"].values[0]\n",
    "            \n",
    "            relationship_choices = VALID_RELATIONSHIPS.get((label_1, label_2), [])\n",
    "            if len(relationship_choices) == 0:\n",
    "                continue\n",
    "            \n",
    "            print(f'evaluation relationship between {entity_1} and {entity_2}')\n",
    "            \n",
    "            random.shuffle(relationship_choices)\n",
    "            \n",
    "            prompt = f\"\"\"You are an entity resolution assistant. \n",
    "            You must classify the relationship between two entities:\n",
    "            Entity 1: name = {entity_1}, type = {label_1} \n",
    "            Entity 2: name = {entity_2}, type = {label_2}\n",
    "        \n",
    "            The valid choices are: {relationship_choices}. If none fit specify NONE.\n",
    "            \n",
    "            Use both your inherent knowledge, and this fact derived from chat logs:\n",
    "            {fact}\n",
    "            \n",
    "            Your response begin with one of the following choices: {relationship_choices}, NONE. \n",
    "            A score from 1 to 100 should follow. 100 means you are very confident in your choice, 1 means you are not confident at all.\n",
    "            Then it should follow with a short explanation of your reasoning.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = client.chat.completions.create(model=model, messages=[{\"role\": \"user\", \"content\": prompt}]).choices[0].message.content\n",
    "            assert(response)\n",
    "            \n",
    "            # first choice to appear in response wins\n",
    "            winner = None\n",
    "            min_idx = float('inf')\n",
    "            for label in relationship_choices:\n",
    "                if label in response:\n",
    "                    idx = response.index(label)\n",
    "                    if idx < min_idx:\n",
    "                        min_idx = idx\n",
    "                        winner = label\n",
    "            # score is regex match for first number in the response\n",
    "            try:\n",
    "                score = int(re.search(r'\\d+', response).group())\n",
    "            except AttributeError:\n",
    "                score = 0\n",
    "                \n",
    "            row = {\"entity_1\": entity_1, \"entity_2\": entity_2, \"relationship\": winner, 'fact': fact, 'score': score}\n",
    "            print(row)\n",
    "            relation_rows.append(row)\n",
    "\n",
    "relation_df = pd.DataFrame(relation_rows)\n",
    "with open('relationships.pkl', 'wb') as f:\n",
    "    relation_df.to_pickle(f)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# check logic,\n",
    "\n",
    "# multiple romantic partners, romantic partners that are also a sibling, familial relationships\n",
    "\n",
    "\n",
    "# need to hone by confidence score or something similar, not every fact is equally important"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
